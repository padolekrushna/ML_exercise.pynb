from transformers import pipeline
import torch

# Create a text2text pipeline
gen = pipeline(
    "text2text-generation",
    model="facebook/bart-base",
    device=0 if torch.cuda.is_available() else -1,
    torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
)

# Build your prompt using emotion_label and test_text
prompt = (
    f"The user is feeling {emotion_label}. "
    f"They said: \"{test_text}\". "
    "Provide 3â€“4 practical, short mental health tips as bullet points."
)

res = gen(prompt, max_new_tokens=100, do_sample=True, top_p=0.9, temperature=0.7)
print("ðŸ§  Mental Health Tips:\n" + res[0]["generated_text"])

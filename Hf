from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

token = "hf_your_actual_token_here"

tokenizer = AutoTokenizer.from_pretrained("TheCarBun/GPT-2-fine-tuned-mental-health", use_auth_token=token)
model = AutoModelForCausalLM.from_pretrained("TheCarBun/GPT-2-fine-tuned-mental-health", use_auth_token=token)

chatbot = pipeline("text-generation", model=model, tokenizer=tokenizer)

user_input = "I feel so alone."
response = chatbot(f"User: {user_input} AI:", max_length=50)

print(response[0]["generated_text"])
